# -*- coding: utf-8 -*-
# weibifan 2022-10-3
# åŸºäºTransformerçš„PLMæ¨¡å‹çš„ä½¿ç”¨ --- PaddleHubæ¨¡æ‹Ÿçš„å¯¹è±¡
# å¤§æ¨¡å‹ç†è®º
# åŸºæœ¬æ–¹æ³•ï¼šâ‘ è®¿é—® https://github.com/huggingface/transformers
# â‘¡  è¿›å…¥æ¨¡å‹ç½‘ç«™ï¼Œçœ‹è¯´æ˜å’Œä»£ç ï¼šhttps://huggingface.co/gpt2

# è¿™é‡Œçš„pipelineå’ŒTorchDataé‡Œé¢çš„pipelineæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ
"""
https://huggingface.co/models  æ¨¡å‹æ£€ç´¢
1ï¼‰ æ‰€æœ‰æ¨¡å‹æ”¾åˆ°https://huggingface.co/ç½‘ç«™ä¸Šã€‚æ”¯æŒPyTorchï¼ŒTFç­‰ï¼Œå‡ ä¹æ²¡æœ‰Paddleå¹³å°ã€‚
2ï¼‰ é€šè¿‡ AutoConfigç±»è®¾ç½®æ¨¡å‹çš„ä¿¡æ¯
3ï¼‰ é€šè¿‡å­—ç¬¦ä¸²æ ‡è¯†ä¸åŒæ¨¡å‹ï¼Œæ¯”å¦‚luhua\\chinese_pretrain_mrc_macbert_large
4ï¼‰é€šè¿‡from_pretrained()å‡½æ•°ä»ç½‘ç«™ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼Œå¹¶åŠ è½½åˆ°cpuçš„mem
5ï¼‰æ¨¡å‹å¤§å°ä¸€èˆ¬åœ¨2Gå·¦å³
9ï¼‰ä¸­æ–‡æ¨¡å‹å¾ˆå°‘

2ç§åŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼š
1ï¼‰åŸºäºPythonçš„ pipeline API
2ï¼‰å¾®æœåŠ¡ç‰ˆThe Inference APIï¼šhuggingfaceä¸Šæ¨¡å‹çš„åœ¨çº¿ç‰ˆ
åœ¨é¡µé¢çš„å³ä¾§ï¼šHosted inference API

è¿™é‡Œçš„æ¨¡å‹åˆ†ä¸º3ç±»ï¼š
1ï¼‰å¤§å‚å‘å¸ƒçš„åŸºç¡€æ¨¡å‹ï¼Œæ¯”å¦‚Googleçš„T5ï¼ŒmT5ï¼ŒOpenAIçš„CLIPï¼ŒGPT2ç­‰ã€‚
2ï¼‰åŸºäºå¤§å‚åŸºç¡€æ¨¡å‹çš„å¾®è°ƒï¼Œæ¯”å¦‚åŸºäºmT5çš„ä¸­æ–‡é—®é¢˜ç”Ÿæˆã€‚
3ï¼‰åŸºäºè®ºæ–‡å®ç°çš„æ¨¡å‹ï¼ŒåŠè¿™äº›æ¨¡å‹çš„å¾®è°ƒç‰ˆï¼Œå°¤å…¶æ˜¯å¤§å‚çš„å¾®è°ƒç‰ˆã€‚

https://huggingface.co/docs/transformers/quicktour

Auto Classesï¼šä¸€ç§ä½¿ç”¨PLMçš„è§„èŒƒ
https://huggingface.co/docs/transformers/model_doc/auto

AutoTokenizerï¼šåŸºäºè¯è¡¨çš„åˆ†è¯å™¨ï¼Œä¸åŒè¯­è¨€è¯¥æ¨¡å‹æœ‰è¾ƒå¤§åŒºåˆ«ã€‚
1ï¼‰ è¯è¡¨ä¸€èˆ¬æ¥æºäºPLMsï¼Œæ‰€ä»¥ä½¿ç”¨from_pretrained()å‡½æ•°è·å¾—ã€‚

AutoFeatureExtractorï¼šWord Embeddingï¼Ÿï¼Ÿï¼Ÿ

å…¸å‹çš„pipelineï¼špipelineå‡½æ•°çš„ç¬¬1ä¸ªå‚æ•°ï¼Œhuggingfaceé¡µé¢å·¦ä¾§çš„ä»»åŠ¡æ ‡ç­¾
feature-extraction (get the vector representation of a text) ï¼šè¯åµŒå…¥
fill-mask ï¼šå®Œå½¢å¡«ç©º
ner (named entity recognition)
question-answering
sentiment-analysisï¼šæ–‡æœ¬åˆ†ç±»
summarization ï¼šT5
text-generation ï¼šGPT2
translation ï¼š
zero-shot-classification

# è‹±æ–‡è¯­æ³•çº é”™ï¼šHuggingface  tuner007/pegasus_paraphrase


æ¯ä¸ªä»»åŠ¡æœ‰å¾ˆå¤šæ¨¡å‹ï¼šæ¯”å¦‚æ–‡æœ¬ç”Ÿæˆä»»åŠ¡åŒ…æ‹¬GPT2ï¼Œdistilgpt2ï¼Œxlnet-base-casedç­‰ã€‚
https://huggingface.co/models?pipeline_tag=text-generation

TransformeråŸç†ï¼š
https://huggingface.co/course/chapter1/4?fw=pt

Checkpointsï¼šæŒ‡æŸä¸ªæ¨¡å‹çš„å‚æ•°

"""
# å…¸å‹æ¡ˆä¾‹ï¼šæ–‡æœ¬åˆ†ç±»
from transformers import pipeline

# æŸ¥çœ‹æºä»£ç ï¼Œæˆ–è€…è®¿é—®ä¸Šé¢ç½‘ç«™ï¼Œå¾—åˆ°pipelineæ‰€æœ‰å¯èƒ½å‚æ•°ï¼Œ
# ç¬¬1ä¸ªå‚æ•°ï¼šä»»åŠ¡ç±»å‹ï¼Œå†³å®šé‚£äº›å‡½æ•°ã€‚å½“æ²¡å®šä¹‰ç¬¬2ä¸ªå‚æ•°æ—¶ï¼Œé€‰æ‹©ä¸€ä¸ªé»˜è®¤æ¨¡å‹ã€‚
# ç¬¬2ä¸ªå‚æ•°ï¼šå…·ä½“çš„æ¨¡å‹ã€‚ä¹Ÿå°±æ˜¯PLMs
classifier = pipeline("sentiment-analysis")

result = classifier("We are very happy to show you the ğŸ¤— Transformers library.")
print(result)
# [{'label': 'POSITIVE', 'score': 0.9998}]

''' 
from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
result = classifier("Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers.")
# [{'label': '5 stars', 'score': 0.7273}]

'''